# recommendation_system.py
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import os
import re

class PostRecommender:
    def __init__(self, model_path='models/recommendation_model.pkl'):
        self.vectorizer = None
        self.tfidf_matrix = None
        self.post_ids = []
        self.post_data = None
        self.model_path = model_path
        self.load_model()

    def preprocess_text(self, text):
        """Ti·ªÅn x·ª≠ l√Ω ti·∫øng Vi·ªát: lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, chuy·ªÉn th∆∞·ªùng, gi·ªØ t·ª´ gh√©p"""
        if not text or not isinstance(text, str):
            return ""
        # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát nh∆∞ng gi·ªØ d·∫•u c√°ch
        text = re.sub(r'[^\w\s√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë]', '', text.lower())
        # Thay nhi·ªÅu kho·∫£ng tr·∫Øng b·∫±ng m·ªôt
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def train(self, posts_df):
        """Hu·∫•n luy·ªán model t·ª´ DataFrame posts"""
        print("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán model g·ª£i √Ω...")

        if 'title' not in posts_df.columns or 'content' not in posts_df.columns:
            print("‚ùå DataFrame thi·∫øu c·ªôt 'title' ho·∫∑c 'content'!")
            return False

        # K·∫øt h·ª£p title + content
        posts_df['full_text'] = (posts_df['title'].fillna('') + " " + posts_df['content'].fillna('')).str.strip()
        posts_df['processed'] = posts_df['full_text'].apply(self.preprocess_text)

        # Lo·∫°i b·ªè b√†i r·ªóng
        posts_df = posts_df[posts_df['processed'].str.strip() != ''].copy()

        if len(posts_df) < 3:
            print(f"‚ö†Ô∏è Ch·ªâ c√≥ {len(posts_df)} b√†i vi·∫øt c√≥ n·ªôi dung ‚Üí kh√¥ng ƒë·ªß ƒë·ªÉ train!")
            return False

        self.post_ids = posts_df['id'].tolist()
        self.post_data = posts_df[['id', 'title', 'content', 'user_id']].to_dict('records')

        # TF-IDF v·ªõi bigram ‚Üí nh·∫≠n di·ªán "l·∫≠t ng·ª≠a", "v·∫≠n ƒë·ªông th√¥", "ƒÉn d·∫∑m", "s·ªët cao"...
        self.vectorizer = TfidfVectorizer(
            max_features=8000,
            ngram_range=(1, 2),           # 1-2 gram r·∫•t quan tr·ªçng cho ti·∫øng Vi·ªát
            min_df=1,                     # Cho ph√©p t·ª´ hi·∫øm (v√¨ d·ªØ li·ªáu m·∫π b·ªâm th∆∞·ªùng √≠t)
            token_pattern=r'(?u)\b\w+\b'  # Gi·ªØ nguy√™n t·ª´ ti·∫øng Vi·ªát
        )

        print(f"Vectorizing {len(posts_df)} documents...")
        self.tfidf_matrix = self.vectorizer.fit_transform(posts_df['processed'])

        self.save_model()
        print(f"‚úÖ Hu·∫•n luy·ªán th√†nh c√¥ng! {len(self.post_ids)} b√†i vi·∫øt ƒë√£ ƒë∆∞·ª£c vector h√≥a.")
        print(f"T·ª´ v·ª±ng m·∫´u: {list(self.vectorizer.vocabulary_.keys())[:10]}...")
        return True

    def save_model(self):
        if not os.path.exists(os.path.dirname(self.model_path)):
            os.makedirs(os.path.dirname(self.model_path))
        with open(self.model_path, 'wb') as f:
            pickle.dump({
                'vectorizer': self.vectorizer,
                'tfidf_matrix': self.tfidf_matrix,
                'post_ids': self.post_ids,
                'post_data': self.post_data
            }, f)
        print(f"üíæ Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {self.model_path}")

    def load_model(self):
        if os.path.exists(self.model_path):
            with open(self.model_path, 'rb') as f:
                data = pickle.load(f)
                self.vectorizer = data.get('vectorizer')
                self.tfidf_matrix = data.get('tfidf_matrix')
                self.post_ids = data.get('post_ids', [])
                self.post_data = data.get('post_data', None)
            print(f"‚úÖ Model ƒë√£ load th√†nh c√¥ng ({len(self.post_ids)} b√†i vi·∫øt)")
        else:
            print("‚ö†Ô∏è Ch∆∞a c√≥ model, c·∫ßn hu·∫•n luy·ªán tr∆∞·ªõc!")

    def get_similar_posts(self, post_id, top_n=5):
        if self.tfidf_matrix is None or not self.post_ids:
            print("Model ch∆∞a ƒë∆∞·ª£c load ho·∫∑c ch∆∞a hu·∫•n luy·ªán!")
            return []

        if post_id not in self.post_ids:
            print(f"‚ö†Ô∏è Post ID {post_id} kh√¥ng c√≥ trong model!")
            return []

        try:
            idx = self.post_ids.index(post_id)
            sim_scores = cosine_similarity(self.tfidf_matrix[idx], self.tfidf_matrix).flatten()
            sim_scores[idx] = 0  # Lo·∫°i b·ªè ch√≠nh n√≥

            top_indices = sim_scores.argsort()[-top_n:][::-1]
            results = []
            for i in top_indices:
                results.append((self.post_ids[i], float(sim_scores[i])))
            return results
        except Exception as e:
            print(f"L·ªói khi t√≠nh similarity: {e}")
            return []

    def recommend_for_user(self, liked_post_ids, top_n=5):
        if self.tfidf_matrix is None or not self.post_ids:
            return []

        valid_liked = [pid for pid in liked_post_ids if pid in self.post_ids]
        if not valid_liked:
            return []

        try:
            liked_indices = [self.post_ids.index(pid) for pid in valid_liked]
            user_vector = self.tfidf_matrix[liked_indices].mean(axis=0)
            sim_scores = cosine_similarity(user_vector, self.tfidf_matrix).flatten()

            # Lo·∫°i b·ªè c√°c b√†i ƒë√£ like
            for idx in liked_indices:
                sim_scores[idx] = 0

            top_indices = sim_scores.argsort()[-top_n:][::-1]
            return [self.post_ids[i] for i in top_indices]
        except Exception as e:
            print(f"L·ªói recommend_for_user: {e}")
            return []


# Kh·ªüi t·∫°o recommender to√†n c·ª•c
recommender = PostRecommender()